Dataflow Operators and Selectors provide a full Dataflow implementation with all the usual ceremony.

h3. Concepts

Full dataflow concurrency builds on the concept of channels connecting operators and selectors, which consume
values coming through input channels, transform them into new values and output the new values into their output channels.
While _Operators_ wait for *all* input channels to have a value available for read before they start process them,
_Selectors_ are triggered by a value available on *any* of the input channels.

{code}
operator(inputs: [a, b, c], outputs: [d]) {x, y, z ->
    ...
    bindOutput 0, x + y + z
}
{code}

{code}
/**
 * CACHE
 *
 * Caches sites' contents. Accepts requests for url content, outputs the content. Outputs requests for download
 * if the site is not in cache yet.
 */
operator(inputs: [urlRequests], outputs: [downloadRequests, sites]) {request ->

    if (!request.content) {
        println "[Cache] Retrieving ${request.site}"
        def content = cache[request.site]
        if (content) {
            println "[Cache] Found in cache"
            bindOutput 1, [site: request.site, word:request.word, content: content]
        } else {
            def downloads = pendingDownloads[request.site]
            if (downloads != null) {
                println "[Cache] Awaiting download"
                downloads << request
            } else {
                pendingDownloads[request.site] = []
                println "[Cache] Asking for download"
                bindOutput 0, request
            }
        }
    } else {
        println "[Cache] Caching ${request.site}"
        cache[request.site] = request.content
        bindOutput 1, request
        def downloads = pendingDownloads[request.site]
        if (downloads != null) {
            for (downloadRequest in downloads) {
                println "[Cache] Waking up"
                bindOutput 1, [site: downloadRequest.site, word:downloadRequest.word, content: request.content]
            }
            pendingDownloads.remove(request.site)
        }
    }
}
{code}

The standard error handling will print out an error message to standard error output and stop the operator in case an uncaught
exception is thrown from withing the operator's body. To alter the behavior, you can redefine the _reportError()_ method
on the operator:

{code}
    op.metaClass.reportError = {Throwable e ->
        //handle the exception
        stop()  //You can also stop the operator
    }
{code}

h4. Types of operators

There are specialized versions of operators serving specific purposes:

  * operator - the basic general-purpose operator
  * selector - operator that is triggered by a value being available in any of its input channels
  * prioritySelector - a selector that prefers delivering messages from lower-indexed input channels over higher-indexed ones
  * splitter - a single-input operator copying its input values to all of its output channels

h4. Chaining operators

Operators are typically combined into networks, when some operators consume output by other operators.

{code}
operator(inputs:[a, b], outputs:[c, d]) {...}
splitter(c, [e, f])
selector(inputs:[e, d]: outputs:[]) {...}
{code}

You may alternatively refer to output channels through operators themselves:

{code}
def op1 = operator(inputs:[a, b], outputs:[c, d]) {...}
def sp1 = splitter(op1.outputs[0], [e, f])                            //takes the first output of op1
selector(inputs:[sp1.outputs[0], op1.outputs[1]]: outputs:[]) {...}   //takes the first output of sp1 and the second output of op1
{code}

h3. Parallelize operators

By default an operator's body is processed by a single thread at a time. While this is a safe setting allowing the operator's
body to be written in a non-thread-safe manner, once an operator becomes "hot" and data start to accumulate in the operator's
input queues, you might consider allowing multiple threads to run the operator's body concurrently. Bear in mind that in such a case
you need to avoid or protect shared resources from multi-threaded access.
To enable multiple threads to run the operator's body concurrently, pass an extra _maxForks_ parameter when creating an operator:

{code}
def op = operator(inputs: [a, b, c], outputs: [d, e], maxForks: 2) {x, y, z ->
    bindOutput 0, x + y + z
    bindOutput 1, x * y * z
}
{code}

The value of the _maxForks_ parameter indicates the maximum of threads running the operator concurrently. Only positive
numbers are allowed with value 1 being the default.

{note}
Please always make sure the *group* serving the operator holds enough threads to support all requested forks.

{code}
def group = new DefaultPGroup(10)
group.operator((inputs: [a, b, c], outputs: [d, e], maxForks: 5) {x, y, z -> ...}
{code}

The default group uses a resizeable thread pool as so will never run out of threads.
{note}

h4. Synchronizing the output

When enabling internal parallelization of an operator by setting the value for _maxForks_ to a value greater than 1
it is important to remember that without explicit or implicit synchronization in the operators' body race-conditions may occur.
Especially bear in mind that values written to multiple output channels are not guarantied to be written atomically in the same order to all the channels
{code}
operator(inputs:[inputChannel], outputs:[a, b], maxForks:5) {msg ->
    bindOutput 0, msg
    bindOutput 1, msg
}
inputChannel << 1
inputChannel << 2
inputChannel << 3
inputChannel << 4
inputChannel << 5
{code}
 May result in output channels having the values mixed-up something like:
{code}
a -> 1, 3, 2, 4, 5
b -> 2, 1, 3, 5, 4
{code}

 Explicit synchronization is one way to get correctly bound all output channels and protect operator not-thread local state:
{code}
def lock = new Object()
operator(inputs:[inputChannel], outputs:[a, b], maxForks:5) {msg ->
    doStuffThatIsThreadSafe()

    synchronized(lock) {
        doSomethingThatMustNotBeAccessedByMultipleThreadsAtTheSameTime()
        bindOutput 0, msg
        bindOutput 1, 2*msg
    }
}
{code}

Obviously you need to weight the pros and cons here, since synchronization may defeat the purpose of setting _maxForks_ to a value greater than 1.

To set values of all the operator's output channels in one atomic step, you may also consider calling either the _bindAllOutputsAtomically_ method, passing in
a single value to write to all output channels or the _bindAllOutputsAtomically_ method, which takes a multiple values, each of which will be written
to the output channel with the same position index.

{code}
operator(inputs:[inputChannel], outputs:[a, b], maxForks:5) {msg ->
    doStuffThatIsThreadSafe()
        bindAllOutputValuesAtomically msg, 2*msg
    }
}
{code}

{note}
 Using the _bindAllOutputs_ or the _bindAllOutputValues_ methods will not guarantee atomicity of writes across al the output channels when using internal parallelism.
 If preserving the order of messages in multiple output channels is not an issue, _bindAllOutputs_ as well as _bindAllOutputValues_ will provide better performance over the atomic variants.
{note}

h4. Stopping operators

Dataflow operators and selectors can be stopped in two ways:
# by calling the stop() method on all operators that need to be stopped
# by sending a poisson message.

Using the stop() method:
{code}
def op1 = operator(inputs: [a, b, c], outputs: [d, e]) {x, y, z -> }

def op2 = selector(inputs: [d], outputs: [f, out]) { }

def op3 = prioritySelector(inputs: [e, f], outputs: [b]) {value, index -> }

[op1, op2, op3]*.stop()  //Stop all operators by calling the stop() method on them
op1.join()
op2.join()
op3.join()
{code}

Using the poisson message:

{code}
def op1 = operator(inputs: [a, b, c], outputs: [d, e]) {x, y, z -> }

def op2 = selector(inputs: [d], outputs: [f, out]) { }

def op3 = prioritySelector(inputs: [e, f], outputs: [b]) {value, index -> }

a << DataFlowPoisson.instance  //Send the poisson

op1.join()
op2.join()
op3.join()
{code}

After receiving a poisson an operator stops. It only makes sure the poisson is first sent to all its output channels, so that the poisson can spread to the connected operators.

h3. Grouping operators

Dataflow operators can be organized into groups to allow for performance fine-tuning. Groups provide a handy _operator()_ factory method
to create tasks attached to the groups.

{code}
import groovyx.gpars.group.DefaultPGroup

def group = new DefaultPGroup()

group.with {
    operator(inputs: [a, b, c], outputs: [d]) {x, y, z ->
        ...
        bindOutput 0, x + y + z
    }
}
{code}

{note:Title=Custom thread pools for dataflow}
The default thread pool for dataflow operators contains daemon threads, which means your application will exit as soon as the main thread finishes and won't wait for all tasks to complete.
When grouping operators, make sure that your custom thread pools either use daemon threads, too, which can be achieved by
using DefaultPGroup or by providing your own thread factory to a thread pool constructor,
or in case your thread pools use non-daemon threads, such as when using the NonDaemonPGroup group class, make sure you shutdown the group or the thread pool explicitly by calling its shutdown() method,
otherwise your applications will not exit.
{note}

h2. Selectors

Selector's body should be a closure consuming either one or two arguments.
{code}
selector ([inputs : [a, b, c], outputs : [d, e]) {value ->
    ....
}
{code}

The two-argument closure will get a value plus an index of the input channel, the value of which is currently being processed.
This allows the selector to distinguish between values coming through different input channels.

{code}
selector ([inputs : [a, b, c], outputs : [d, e]) {value, index ->
    ....
}
{code}

h3. Priority Selector

When priorities need to be preserved among input channels, a _DataFlowPrioritySelector_ should be used.

{code}
prioritySelector[inputs : [a, b, c], outputs : [d, e]) {value, index ->
    ...
}
{code}

The priority selector will always prefer values from channels with lower position index over values coming through the channels with higher position index.

h3. Join selector

A selector without a body closure specified will copy all incoming values to all of its output channels.

{code}
def join = selector ([inputs : [programmers, analysis, managers], outputs : [employees, colleagues])
{code}

h3. Internal parallelism

The _maxForks_ attribute allowing for internal selectors parallelism is also available.

{code}
selector ([inputs : [a, b, c], outputs : [d, e], maxForks : 5) {value ->
    ....
}
{code}

h3. Guards

Just like _Selects_ , _Selectors_ also allow the users to temporarily include/exclude individual input channels from selection.
The _guards_ input property can be used to set the initial mask on all input channels and the _setGuards_ and _setGuard_ methods
are then available in the selector's body.

{code}
import groovyx.gpars.dataflow.DataFlowQueue
import static groovyx.gpars.dataflow.DataFlow.selector
import static groovyx.gpars.dataflow.DataFlow.task

/**
 * Demonstrates the ability to enable/disable channels during a value selection on a select by providing boolean guards.
 */
final DataFlowQueue operations = new DataFlowQueue()
final DataFlowQueue numbers = new DataFlowQueue()

def instruction
def nums = []

selector(inputs: [operations, numbers], outputs: [], guards: [true, false]) {value, index ->   //initial guards is set here
    if (index == 0) {
        instruction = value
        setGuard(0, false)  //setGuard() used here
        setGuard(1, true)
    }
    else nums << value
    if (nums.size() == 2) {
        setGuards([true, false])                                    //setGuards() used here
        final def formula = "${nums[0]} $instruction ${nums[1]}"
        println "$formula = ${new GroovyShell().evaluate(formula)}"
        nums.clear()
    }
}

task {
    operations << '+'
    operations << '+'
    operations << '*'
}

task {
    numbers << 10
    numbers << 20
    numbers << 30
    numbers << 40
    numbers << 50
    numbers << 60
}
{code}

{note}
Avoid combining _guards_ and _maxForks_ greater than 1. Although the _Selector_ is thread-safe and won't be damaged in any way, the guards are likely not to be set
the way you expect. The multiple threads running selector's body concurrently will tend to over-write each-other's settings to the _guards_ property.
{note}