
= Remoting

Concepts like Actors, Dataflows and Agents are not restricted just to single VM,
where they provide an abstraction layer for concurrent programming
that allows to separate logic from low level synchronization code.
These concepts can be easly extended to multiple nodes in a network.
Following chapter describes remoting in GPars.

*Remark*: Remoting for GPars was a _Google Summer of Code 2014_ project.

== Introduction

For each structure(?) a new remote proxy object was introduced (with _Remote_ prefix).
This proxy object usually has the same interface as its local counterpart.
Under the hood it just sends messages to original instance.
To transport messages across the network http://netty.io[Netty] library was used.

Acquiring a remote proxy is done in following way:

. Original instance is published on _hostA:port_ under a specified _name_.
. _hostB_ asks _hostA:port_ for an instance with specified _name_.
. Promise is returned. It will eventually hold a proxy object instance.

To create a proxy-object instance serialization mechanism is used (more <<remote-serialization>>).

At this moment a new connection is created for each request.

[#remote-serialization]
=== Serialization

Following mechanism was used to create proxy objects:

object <-(serialization)-> handle ---(network)--- handle <-(serialization)-> proxy-object

One of the main advantages of this mechanism is
that sending proxy-object reference back is deserialized to original instance.

As all messages are seralized before sending over a wire,
they must implement _Serializable_ interface.
This is a consequence of using build-in Java serialization mechanism and Netty's _ObjectDecoder/ObjectEncoder_.
On the other hand it allows flexibility to send any custom object as a message to Actor
or to use DataflowVariable of any type.

== Dataflows

In order to use remoting for Dataflows, a context (_RemoteDataflows_ class) has to be created.
Within this conext dataflows are published and retrieved from remote hosts.

[source,groovy]
----
def remoteDataflows = RemoteDataflows.create()
----

When the context is created, if you want to able other hosts to retrieve published dataflows,
you need to start server. You need to provied address and port to listen on (eq. _localhost_:11222,
10.0.0.123:11333).

[source,groovy]
----
remoteDataflows.startServer HOST PORT
----

To stop the server, there is _stopServer()_ method. Note that both method are asynchronous,
they don't block - server is started/stopped in background.

*Remark*: To only retrieve instances from remote hosts starting a server is not necessary.

=== DataflowVariable

DataflowVariable is a core part of Dataflows that received remoting abilities.
Other structures(?) depend on it.

When the context is created, publishing a variable is done simply by:

[source,groovy]
----
def variable = new DataflowVariable()
remoteDataflows.publish variable "my-first-variable"
----

It registers the variable under given name, so when a request for variable with name _my-first-variable_ comes,
it can be sent to remote host.
It's important to remember, that publishing another variable under the same name,
will override the provious one and subsequent requests will send newly published one.

Retrieving of a variable is done by:

[source,groovy]
----
def remoteVariablePromise = remoteDataflows.getVariable HOST, PORT, "my-first-variable"
def remoteVariable = remoteVariablePromise.get()
----

The _getVariable_ method is non-blocking and returns promise, that will eventually hold a proxy to variable.
This proxy has the same interface as DataflowVariable and can be used seemlessly as regular variable.

To explore a full example see: _..._

=== DataflowBroadcast

It's possible to subscribe to DataflowBroadcast on remote host.
To do this, one had to publish it first (assuming that context is already created):

[source,groovy]
----
def stream = new DataflowBroadcast()
remoteDataflows.publish stream "my-first-broadcast"
----

Then on other host it can be retrieved:

[source,groovy]
----
def readChannelPromise = remoteDataflows.getReadChannel HOST, PORT, "my-first-broadcast"
def readChannel = readChannelPromise.get()
----

Obtainted proxy object has the same interface as ReadChannel
and can be used in same fashion as ReadChannel of regular DataflowBroadcast.

To explore a full example see: _..._

=== DataflowQueue

DataflowQueue received similar functionality. It can be published:

[source,groovy]
----
def queue = new DataflowQueue()
remoteDataflows.publish queue, "my-first-queue"
----

and in similar way retrieved on remote host:

[source,groovy]
----
def queuePromise = remoteDataflows.getQueue HOST, PORT, "my-first-queue"
def queue = queuePromise.get()
----

Pushing into this queue will push into its original instance.
Retrieval work exactly like on single machine.

To explore a full example see: _..._ or _..._

== Actors

TBD

== Agents

work in progress